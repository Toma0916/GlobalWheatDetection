{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Pytorch starter - FasterRCNN Inference\n\n- You can find the [train notebook here](https://www.kaggle.com/pestipeti/pytorch-starter-fasterrcnn-train)\n- The weights are [available here](https://www.kaggle.com/dataset/7d5f1ed9454c848ecb909c109c6fa8e573ea4de299e249c79edc6f47660bf4c5)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport cv2\nimport os, sys\nimport re\n\nfrom PIL import Image\n\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport torch\nimport torchvision\n\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection import FasterRCNN\nfrom torchvision.models.detection.rpn import AnchorGenerator\n\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SequentialSampler\n\nfrom matplotlib import pyplot as plt\n\nsys.path.append('/kaggle/input/my-wbf')\nfrom ensemble_boxes_wbf import *\n\nDIR_INPUT = '/kaggle/input/global-wheat-detection'\nDIR_TRAIN = f'{DIR_INPUT}/train'\nDIR_TEST = f'{DIR_INPUT}/test'\n\nDIR_WEIGHTS = '/kaggle/input/weight-baseline'\n\nWEIGHTS_FILE = f'{DIR_WEIGHTS}/fasterrcnn_resnet50_fpn_best.pth'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv2.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.__version__","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(f'{DIR_INPUT}/sample_submission.csv')\ntest_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass TTA_Model:\n    def __init__(self, model, device, cpu_device):\n        self.model = model\n        self.device = device\n        self.cpu_device = cpu_device\n        self.transforms = [A.Compose([A.HorizontalFlip(p=0), ToTensorV2(p=1)], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']}),\n            A.Compose([A.HorizontalFlip(p=1), ToTensorV2(p=1)], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']}),\n            A.Compose([A.VerticalFlip(p=1), ToTensorV2(p=1)], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']}),\n            A.Compose([A.HorizontalFlip(p=1), A.VerticalFlip(p=1), ToTensorV2(p=1)], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})]\n        self.transforms_inv = [A.Compose([A.HorizontalFlip(p=0), ToTensorV2(p=1)], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']}),\n            A.Compose([A.HorizontalFlip(p=1), ToTensorV2(p=1)], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']}),\n            A.Compose([A.VerticalFlip(p=1), ToTensorV2(p=1)], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']}),\n            A.Compose([A.HorizontalFlip(p=1), A.VerticalFlip(p=1), ToTensorV2(p=1)], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})]\n    \n    def __call__(self, image, postprocess=2):\n        sample = {\n            'image': image.permute(1, 2, 0).data.cpu().numpy(),\n            'bboxes': [[2.0000e+02, 3.3600e+02, 2.3900e+02, 3.7000e+02]],\n            'labels': [1]\n        }\n        samples = [transform(**sample) for transform in self.transforms]\n        ts_images = list(sample['image'].to(self.device) for sample in samples)\n        outputs_transformed = self.model(ts_images)\n        outputs_transformed = [{k: v.to(self.cpu_device) for k, v in t.items()} for t in outputs_transformed]\n        samples_transformed = [{'image':image.permute(1, 2, 0).data.cpu().numpy(),\n                                'bboxes':output['boxes'],\n                                'labels':[1 for _ in output['boxes']]} for output in outputs_transformed]\n        outputs = [t(**s) for t, s in zip(self.transforms_inv, samples_transformed)]\n        boxes = []\n        scores = []\n        labels = []\n        for idx in range(len(outputs)):\n            boxes += outputs[idx]['bboxes']\n            scores += outputs_transformed[idx]['scores'].data.cpu().numpy().tolist()\n            labels += [1 for _ in outputs_transformed[idx]['scores']]\n        if postprocess==0:\n            final_boxes, final_scores, final_labels = np.array(boxes[0]), np.array(scores[0]), np.array(labels[0])\n        elif postprocess==1:\n            final_boxes, final_scores, final_labels = soft_nms(boxes, scores, labels, method=2, iou_thr=0.3, sigma=1.0, thresh=0.001, weights=None)\n        elif postprocess==2:\n            image_size = (np.sum(image.shape)-3)/2\n            boxes = [np.array(box)/(image_size-1) for box in boxes]\n            final_boxes, final_scores, final_labels = weighted_boxes_fusion([boxes],\n                                                                            [scores],\n                                                                            [labels],\n                                                                            weights=None,\n                                                                            iou_thr=0.7,\n                                                                            skip_box_thr=0.7)\n            final_boxes = np.array(final_boxes) * (image_size-1)\n        return {'boxes': final_boxes, 'scores':final_scores, 'labels':final_labels}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\ndef cpu_soft_nms_float(dets, sc, Nt, sigma, thresh, method):\n    \"\"\"\n    Based on: https://github.com/DocF/Soft-NMS/blob/master/soft_nms.py\n    It's different from original soft-NMS because we have float coordinates on range [0; 1]\n    :param dets:   boxes format [x1, y1, x2, y2]\n    :param sc:     scores for boxes\n    :param Nt:     required iou \n    :param sigma:  \n    :param thresh: \n    :param method: 1 - linear soft-NMS, 2 - gaussian soft-NMS, 3 - standard NMS\n    :return:       index of boxes to keep\n    \"\"\"\n\n    # indexes concatenate boxes with the last column\n    N = dets.shape[0]\n    indexes = np.array([np.arange(N)])\n    dets = np.concatenate((dets, indexes.T), axis=1)\n\n    # the order of boxes coordinate is [y1, x1, y2, x2]\n    y1 = dets[:, 1]\n    x1 = dets[:, 0]\n    y2 = dets[:, 3]\n    x2 = dets[:, 2]\n    scores = sc\n    areas = (x2 - x1) * (y2 - y1)\n\n    for i in range(N):\n        # intermediate parameters for later parameters exchange\n        tBD = dets[i, :].copy()\n        tscore = scores[i].copy()\n        tarea = areas[i].copy()\n        pos = i + 1\n\n        #\n        if i != N - 1:\n            maxscore = np.max(scores[pos:], axis=0)\n            maxpos = np.argmax(scores[pos:], axis=0)\n        else:\n            maxscore = scores[-1]\n            maxpos = 0\n        if tscore < maxscore:\n            dets[i, :] = dets[maxpos + i + 1, :]\n            dets[maxpos + i + 1, :] = tBD\n            tBD = dets[i, :]\n\n            scores[i] = scores[maxpos + i + 1]\n            scores[maxpos + i + 1] = tscore\n            tscore = scores[i]\n\n            areas[i] = areas[maxpos + i + 1]\n            areas[maxpos + i + 1] = tarea\n            tarea = areas[i]\n\n        # IoU calculate\n        xx1 = np.maximum(dets[i, 1], dets[pos:, 1])\n        yy1 = np.maximum(dets[i, 0], dets[pos:, 0])\n        xx2 = np.minimum(dets[i, 3], dets[pos:, 3])\n        yy2 = np.minimum(dets[i, 2], dets[pos:, 2])\n\n        w = np.maximum(0.0, xx2 - xx1)\n        h = np.maximum(0.0, yy2 - yy1)\n        inter = w * h\n        ovr = inter / (areas[i] + areas[pos:] - inter)\n\n        # Three methods: 1.linear 2.gaussian 3.original NMS\n        if method == 1:  # linear\n            weight = np.ones(ovr.shape)\n            weight[ovr > Nt] = weight[ovr > Nt] - ovr[ovr > Nt]\n        elif method == 2:  # gaussian\n            weight = np.exp(-(ovr * ovr) / sigma)\n        else:  # original NMS\n            weight = np.ones(ovr.shape)\n            weight[ovr > Nt] = 0\n\n        scores[pos:] = weight * scores[pos:]\n\n    # select the boxes and keep the corresponding indexes\n    inds = dets[:, 4][scores > thresh]\n    keep = inds.astype(int)\n    return keep\n\n\ndef nms_float_fast(dets, scores, thresh):\n    \"\"\"\n    # It's different from original nms because we have float coordinates on range [0; 1]\n    :param dets: numpy array of boxes with shape: (N, 5). Order: x1, y1, x2, y2, score. All variables in range [0; 1]\n    :param thresh: IoU value for boxes\n    :return: \n    \"\"\"\n    x1 = dets[:, 0]\n    y1 = dets[:, 1]\n    x2 = dets[:, 2]\n    y2 = dets[:, 3]\n\n    areas = (x2 - x1) * (y2 - y1)\n    order = scores.argsort()[::-1]\n\n    keep = []\n    while order.size > 0:\n        i = order[0]\n        keep.append(i)\n        xx1 = np.maximum(x1[i], x1[order[1:]])\n        yy1 = np.maximum(y1[i], y1[order[1:]])\n        xx2 = np.minimum(x2[i], x2[order[1:]])\n        yy2 = np.minimum(y2[i], y2[order[1:]])\n\n        w = np.maximum(0.0, xx2 - xx1)\n        h = np.maximum(0.0, yy2 - yy1)\n        inter = w * h\n        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n        inds = np.where(ovr <= thresh)[0]\n        order = order[inds + 1]\n\n    return keep\n\n\ndef nms_method(boxes, scores, labels, method=3, iou_thr=0.5, sigma=0.5, thresh=0.001, weights=None):\n    \"\"\"\n    :param boxes: list of boxes predictions from each model, each box is 4 numbers. \n    It has 3 dimensions (models_number, model_preds, 4)\n    Order of boxes: x1, y1, x2, y2. We expect float normalized coordinates [0; 1] \n    :param scores: list of scores for each model \n    :param labels: list of labels for each model\n    :param method: 1 - linear soft-NMS, 2 - gaussian soft-NMS, 3 - standard NMS\n    :param iou_thr: IoU value for boxes to be a match \n    :param sigma: Sigma value for SoftNMS\n    :param thresh: threshold for boxes to keep (important for SoftNMS)\n    :param weights: list of weights for each model. Default: None, which means weight == 1 for each model\n    :return: boxes: boxes coordinates (Order of boxes: x1, y1, x2, y2). \n    :return: scores: confidence scores\n    :return: labels: boxes labels\n    \"\"\"\n\n    # If weights are specified\n    if weights is not None:\n        if len(boxes) != len(weights):\n            print('Incorrect number of weights: {}. Must be: {}. Skip it'.format(len(weights), len(boxes)))\n        else:\n            weights = np.array(weights)\n            for i in range(len(weights)):\n                scores[i] = (np.array(scores[i]) * weights[i]) / weights.sum()\n\n    # We concatenate everything\n    boxes = np.concatenate(boxes)\n    scores = np.concatenate(scores)\n    labels = np.concatenate(labels)\n\n    # Run NMS independently for each label\n    unique_labels = np.unique(labels)\n    final_boxes = []\n    final_scores = []\n    final_labels = []\n    for l in unique_labels:\n        condition = (labels == l)\n        boxes_by_label = boxes[condition]\n        scores_by_label = scores[condition]\n        labels_by_label = np.array([l] * len(boxes_by_label))\n\n        if method != 3:\n            keep = cpu_soft_nms_float(boxes_by_label.copy(), scores_by_label.copy(), Nt=iou_thr, sigma=sigma, thresh=thresh, method=method)\n        else:\n            # Use faster function\n            keep = nms_float_fast(boxes_by_label, scores_by_label, thresh=iou_thr)\n\n        final_boxes.append(boxes_by_label[keep])\n        final_scores.append(scores_by_label[keep])\n        final_labels.append(labels_by_label[keep])\n    final_boxes = np.concatenate(final_boxes)\n    final_scores = np.concatenate(final_scores)\n    final_labels = np.concatenate(final_labels)\n\n    return final_boxes, final_scores, final_labels\n\n\ndef nms(boxes, scores, labels, iou_thr=0.5, weights=None):\n    \"\"\"\n    Short call for standard NMS \n    \n    :param boxes: \n    :param scores: \n    :param labels: \n    :param iou_thr: \n    :param weights: \n    :return: \n    \"\"\"\n    return nms_method(boxes, scores, labels, method=3, iou_thr=iou_thr, weights=weights)\n\n\ndef soft_nms(boxes, scores, labels, method=2, iou_thr=0.5, sigma=0.5, thresh=0.001, weights=None):\n    \"\"\"\n    Short call for Soft-NMS\n     \n    :param boxes: \n    :param scores: \n    :param labels: \n    :param method: \n    :param iou_thr: \n    :param sigma: \n    :param thresh: \n    :param weights: \n    :return: \n    \"\"\"\n    return nms_method(boxes, scores, labels, method=method, iou_thr=iou_thr, sigma=sigma, thresh=thresh, weights=weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class WheatTestDataset(Dataset):\n\n    def __init__(self, dataframe, image_dir, transforms=None):\n        super().__init__()\n\n        self.image_ids = dataframe['image_id'].unique()\n        self.df = dataframe\n        self.image_dir = image_dir\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n\n        image_id = self.image_ids[index]\n        records = self.df[self.df['image_id'] == image_id]\n\n        image = cv2.imread(f'{self.image_dir}/{image_id}.jpg', cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n\n        if self.transforms:\n            sample = {\n                'image': image,\n            }\n            sample = self.transforms(**sample)\n            image = sample['image']\n\n        return image, image_id\n\n    def __len__(self) -> int:\n        return self.image_ids.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Albumentations\ndef get_test_transform():\n    return A.Compose([\n        # A.Resize(512, 512),\n        ToTensorV2(p=1.0)\n    ])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load a model; pre-trained on COCO\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ncpu_device = torch.device('cpu')\n\nnum_classes = 2  # 1 class (wheat) + background\n\n# get number of input features for the classifier\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n\n# replace the pre-trained head with a new one\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\n# Load the trained weights\nmodel.load_state_dict(torch.load(WEIGHTS_FILE))\nmodel.eval()\n\nx = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def collate_fn(batch):\n    return tuple(zip(*batch))\n\ntest_dataset = WheatTestDataset(test_df, DIR_TEST, get_test_transform())\n\ntest_data_loader = DataLoader(\n    test_dataset,\n    batch_size=1,\n    shuffle=False,\n    num_workers=4,\n    drop_last=False,\n    collate_fn=collate_fn\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_prediction_string(boxes, scores):\n    pred_strings = []\n    for j in zip(scores, boxes):\n        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n\n    return \" \".join(pred_strings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detection_threshold = 0.5\nresults = []\npostprocess = 0\ntta_model = TTA_Model(model, device, cpu_device)\nfor images, image_ids in test_data_loader:\n\n    output = tta_model(images[0])\n    final_boxes = output['boxes']\n    final_scores = output['scores'] \n    final_labels = output['labels']\n    #     for i, image in enumerate(images):\n    #         # print(outputs[i]['boxes'].detach(), outputs[i]['scores'].detach()) \n    #         boxes = [outputs[i]['boxes'].data.cpu().numpy().tolist()]\n    #         scores = [outputs[i]['scores'].data.cpu().numpy().tolist()]\n    #         labels = [[1 for _ in scores[0]]]\n    #         if postprocess==0:\n    #             final_boxes, final_scores, final_labels = np.array(boxes[0]), np.array(scores[0]), np.array(labels[0])\n    #         elif postprocess==1:\n    #             final_boxes, final_scores, final_labels = soft_nms(boxes, scores, labels, method=2, iou_thr=0.5, sigma=0.5, thresh=0.001, weights=None)\n    #         elif postprocess==2:\n    #             image_size = (np.sum(image.shape)-3)/2\n    #             boxes = [np.array(box)/(image_size-1) for box in boxes]\n    #             final_boxes, final_scores, final_labels = weighted_boxes_fusion(boxes,\n    #                                                                             scores,\n    #                                                                             labels,\n    #                                                                             weights=None,\n    #                                                                             iou_thr=0.7,\n    #                                                                             skip_box_thr=0.7)\n    #             final_boxes = np.array(final_boxes) * (image_size-1)\n    #         final_boxes = final_boxes[final_scores >= detection_threshold].astype(np.int32)\n    #         final_scores = final_scores[final_scores >= detection_threshold]\n    image_id = image_ids[0]\n        \n    final_boxes[:, 2] = final_boxes[:, 2] - final_boxes[:, 0]\n    final_boxes[:, 3] = final_boxes[:, 3] - final_boxes[:, 1]\n\n    result = {\n        'image_id': image_id,\n        'PredictionString': format_prediction_string(final_boxes, final_scores)\n    }\n\n    results.append(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results[0:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample = images[1].permute(1,2,0).cpu().numpy()\n# boxes = outputs[1]['boxes'].data.cpu().numpy()\n# scores = outputs[1]['scores'].data.cpu().numpy()\n\n# boxes = boxes[scores >= detection_threshold].astype(np.int32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n\n# for box in boxes:\n#     cv2.rectangle(sample,\n#                   (box[0], box[1]),\n#                   (box[2], box[3]),\n#                   (220, 0, 0), 2)\n    \n# ax.set_axis_off()\n# ax.imshow(sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}